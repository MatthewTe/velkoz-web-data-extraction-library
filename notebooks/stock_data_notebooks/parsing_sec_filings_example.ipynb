{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Velkoz Web Scraping Library Processes and Writes SEC Filings Data to its Backend\n",
    "\n",
    "Typically stock data exists in formats that are easy to parse and format such as price time-series data or tabular data regarding earnings reports. However there exists a larger area of analysis to be done regarding data that is more difficult to parse. This notebook explains the process of how SEC listings data such as 10-Ks and 8-Ks are scraped, transformed into structured data and written to a backend database. \n",
    "\n",
    "Note that the core logic is basically shamelessly ripped off from the Sigma Coding series of tutorials on how to extract data from SEC filings found here:\n",
    "\n",
    "https://www.youtube.com/playlist?list=PLcFcktZ0wnNl5X7Qn1JM4jhrIOBsNj1qa \n",
    "\n",
    "\n",
    "I am experimenting on making notebooks the primary means of documenting the velkoz_web_data_extraction_library modules as writing sphinx documentation is making me physically ill.\n",
    "\n",
    "The notebook describes the logic that will be used to build the two core modules that the velkoz library uses to extract data:\n",
    "\n",
    "* A Data Ingestion Engine\n",
    "* A Page Response Object\n",
    "\n",
    "## A Note on SEC Raw Data Extraction Formats and External Library Use:\n",
    "\n",
    "The main logic around web scraping (sending the HTTP requests to the SEC server and receiving the response containing the .txt file) is outsourced to the python library `sec-edgar-downloader`. \n",
    "\n",
    "It is responsible for extracting the raw web data, the velkoz library methods are essentially wrappers that wrap the sigma_coding logic into a format that is consistent with the velkoz library format. This notebook will contain all of the necessary logic outlining this process.  \n",
    "\n",
    "Instead of using the `sec-edgar-downloader` to extract a raw txt file from SEC servers for use in this notebook a txt file containing data in the same format stored in the `tests` directory will be used. \n",
    "\n",
    "Relative path to the example txt file used: `../tests/static_test_files/static_files_stock_data_test/0000320193-20-000096.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing 3rd Party Packages:\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In actual module data would be passed from a WebPageResponseObject after making a request instead of read from a static test file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening raw txt output as a Beautifulsoup object to be parsed:\n",
    "path_to_data = \"../../tests/static_test_files/static_files_stock_data_test/0000320193-20-000096.txt\"\n",
    "with open(path_to_data) as file:\n",
    "    content = file.read()\n",
    "soup = BeautifulSoup(content, 'lxml') # Should use lxml parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like sigma_coding the velkoz library will return the parsed contents of the filing within a nested dictionary `master_document_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty dictionaries to be populated with parsed filings data:\n",
    "master_document_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not Interested in the SEC Header and are more interested in the main body of content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "+------------------------------------------------------------------------------+\n",
    "|   CODE BELOW DIRECTLY TAKEN FROM Sigma_Coding YOUTUBE TUTORIAL FOUND AT:     |\n",
    "|                                                                              |\n",
    "|   https://github.com/areed1192/sigma_coding_youtube                          |\n",
    "+------------------------------------------------------------------------------+\n",
    "\"\"\"\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Complete Code Examination of Sigma_Codes notebooks to adapt code.\n",
    "* Determine what structuring has changed in SEC EDGAR that has caused Sigma_Code scripts to fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
